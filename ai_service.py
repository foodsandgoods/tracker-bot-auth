"""
AI service for generating issue summaries using GPTunnel API.
Uses shared HTTP client and includes retry logic with graceful degradation.
"""
import asyncio
import logging
from typing import Optional, Tuple

from config import settings
from http_client import get_client, get_timeout
from metrics import metrics

logger = logging.getLogger(__name__)

# Graceful degradation messages
FALLBACK_MESSAGES = {
    "not_configured": "âš ï¸ AI-ÑÐµÑ€Ð²Ð¸Ñ Ð½Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½. ÐžÐ±Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÑÑŒ Ðº Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ñƒ.",
    "timeout": "â±ï¸ AI-ÑÐµÑ€Ð²Ð¸Ñ Ð½Ðµ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.",
    "rate_limit": "ðŸš« ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ðº AI. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‡ÐµÑ€ÐµÐ· Ð¼Ð¸Ð½ÑƒÑ‚Ñƒ.",
    "auth_error": "ðŸ” ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸ AI-ÑÐµÑ€Ð²Ð¸ÑÐ°. ÐžÐ±Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÑÑŒ Ðº Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ñƒ.",
    "server_error": "âš ï¸ AI-ÑÐµÑ€Ð²Ð¸Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.",
    "unknown": "âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐ·ÑŽÐ¼Ðµ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.",
}


def _build_prompt(issue_data: dict) -> str:
    """Build structured prompt from issue data."""
    key = issue_data.get("key", "")
    summary = issue_data.get("summary", "")
    description = issue_data.get("description", "") or "ÐÐµÑ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ"
    
    status = "ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½"
    if isinstance(issue_data.get("status"), dict):
        status = issue_data["status"].get("display", "ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½")
    
    assignee = "ÐÐµ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½"
    if isinstance(issue_data.get("assignee"), dict):
        assignee = issue_data["assignee"].get("display", "ÐÐµ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½")
    
    # Last 5 comments
    comments = issue_data.get("comments", [])
    comments_text = ""
    if comments and isinstance(comments, list):
        comments_list = []
        for c in comments[-5:]:
            if isinstance(c, dict):
                author = "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾"
                if isinstance(c.get("createdBy"), dict):
                    author = c["createdBy"].get("display", "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾")
                text = (c.get("text") or "").strip()
                if text:
                    comments_list.append(f"  â€¢ {author}: {text[:150]}")
        if comments_list:
            comments_text = "\n".join(comments_list)
    
    # Checklist items
    checklist = issue_data.get("checklistItems", [])
    checklist_text = ""
    if checklist and isinstance(checklist, list):
        checklist_list = []
        for item in checklist[:5]:
            if isinstance(item, dict):
                checked = "âœ…" if item.get("checked", False) else "â¬œ"
                text = (item.get("text") or "").strip()
                if text:
                    checklist_list.append(f"  {checked} {text[:100]}")
        if checklist_list:
            checklist_text = "\n".join(checklist_list)
    
    # Limit description length
    desc_limited = description[:800] if len(description) > 800 else description
    
    return f"""Ð¡Ð¾ÑÑ‚Ð°Ð²ÑŒ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸Ð· Yandex Tracker (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 500 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²).

Ð—Ð°Ð´Ð°Ñ‡Ð°: {key} â€” {summary}
Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: {status}
Ð˜ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒ: {assignee}

ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ:
{desc_limited}

Ð§ÐµÐºÐ»Ð¸ÑÑ‚:
{checklist_text if checklist_text else "ÐÐµÑ‚ Ñ‡ÐµÐºÐ»Ð¸ÑÑ‚Ð°"}

ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸:
{comments_text if comments_text else "ÐÐµÑ‚ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²"}

Ð¡Ð¾ÑÑ‚Ð°Ð²ÑŒ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:
1. Ð¦ÐµÐ»ÑŒ Ð·Ð°Ð´Ð°Ñ‡Ð¸ (1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ)
2. Ð¢ÐµÐºÑƒÑ‰Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ
3. ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹ Ð¸Ð· Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ
4. ÐŸÑ€Ð¾Ð³Ñ€ÐµÑÑ Ð¿Ð¾ Ñ‡ÐµÐºÐ»Ð¸ÑÑ‚Ñƒ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)
5. ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ/ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)

Ð ÐµÐ·ÑŽÐ¼Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¼ (Ð´Ð¾ 500 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²) Ð¸ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ."""


def _extract_content(data: dict) -> Optional[str]:
    """Extract content from API response."""
    if "choices" in data and isinstance(data["choices"], list) and len(data["choices"]) > 0:
        choice = data["choices"][0]
        if isinstance(choice, dict) and "message" in choice:
            message = choice["message"]
            if isinstance(message, dict):
                content = message.get("content", "")
                if content and isinstance(content, str):
                    return content.strip()
    return None


async def _make_request(
    client,
    url: str,
    headers: dict,
    payload: dict,
    timeout
) -> Tuple[int, dict]:
    """Make HTTP request to AI API."""
    try:
        r = await client.post(url, headers=headers, json=payload, timeout=timeout)
        try:
            data = r.json()
        except Exception:
            data = {"raw": r.text[:500] if r.text else ""}
        return r.status_code, data
    except Exception as e:
        return 0, {"error": str(e)}


async def generate_summary(issue_data: dict) -> Tuple[Optional[str], Optional[str]]:
    """
    Generate summary for issue using GPTunnel API.
    
    Uses shared HTTP client and includes retry with exponential backoff.
    Returns user-friendly error messages for graceful degradation.
    
    Args:
        issue_data: Issue data from Yandex Tracker
    
    Returns:
        Tuple of (summary_text, error_message)
    """
    metrics.inc("ai.requests")
    
    if not settings.ai:
        metrics.inc("ai.not_configured")
        return None, FALLBACK_MESSAGES["not_configured"]
    
    ai_config = settings.ai
    prompt = _build_prompt(issue_data)
    
    payload = {
        "model": ai_config.model,
        "messages": [
            {
                "role": "system",
                "content": "Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑÐ¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ð·Ð°Ð´Ð°Ñ‡. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ, Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ ÐºÑ€Ð°Ñ‚ÐºÐ¾."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "useWalletBalance": True,
        "max_tokens": ai_config.max_tokens,
        "temperature": ai_config.temperature,
    }
    
    client = await get_client()
    timeout = get_timeout(long=True)
    
    # Try different auth methods
    auth_variants = [
        {"Authorization": ai_config.api_key, "Content-Type": "application/json"},
        {"Authorization": f"Bearer {ai_config.api_key}", "Content-Type": "application/json"},
    ]
    
    last_error = None
    
    for attempt in range(ai_config.max_retries):
        for headers in auth_variants:
            try:
                status, data = await _make_request(
                    client, ai_config.api_url, headers, payload, timeout
                )
                
                if status == 0:
                    # Connection error
                    last_error = data.get("error", "Connection error")
                    continue
                
                if status == 200:
                    # Check for API error codes in response
                    if "code" in data and data.get("code") != 0:
                        code = data.get("code")
                        if code == 5:  # Insufficient balance
                            last_error = "server_error"
                        elif code == 6:  # Overloaded
                            last_error = "rate_limit"
                        else:
                            last_error = "server_error"
                        continue
                    
                    content = _extract_content(data)
                    if content:
                        # Truncate if too long
                        if len(content) > 500:
                            content = content[:497] + "..."
                        metrics.inc("ai.success")
                        return content, None
                    
                    last_error = "unknown"
                    continue
                
                if status == 401:
                    # Try next auth variant
                    last_error = "auth_error"
                    continue
                
                if status == 429:
                    # Rate limited - wait and retry
                    last_error = "rate_limit"
                    metrics.inc("ai.rate_limited")
                    await asyncio.sleep(2 ** attempt)
                    continue
                
                if status >= 500:
                    # Server error - retry
                    last_error = "server_error"
                    await asyncio.sleep(1)
                    continue
                
                # Other error
                last_error = "unknown"
                
            except asyncio.TimeoutError:
                last_error = "timeout"
                metrics.inc("ai.timeout")
                continue
            except Exception as e:
                last_error = "unknown"
                metrics.inc("ai.error")
                logger.debug(f"AI request error: {e}")
                continue
        
        # Wait before retry
        if attempt < ai_config.max_retries - 1:
            await asyncio.sleep(1.5 ** attempt)
    
    # Return user-friendly error message
    metrics.inc("ai.failed")
    error_key = last_error if last_error in FALLBACK_MESSAGES else "unknown"
    return None, FALLBACK_MESSAGES.get(error_key, FALLBACK_MESSAGES["unknown"])
